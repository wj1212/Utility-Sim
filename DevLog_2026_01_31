When thinking about the underlying logic of this project, the first major question I faced was: How should an NPC "perceive" this world? After some research, I realized that modern life simulation games seem to follow two very different architectural paths: the "Broadcasting" system used by The Sims, and the "Scanning" system seen in games like RimWorld.

The initial spark for this project came from my childhood memories of The Sims. I spent countless hours playing it, but I always felt that the NPCs weren't quite "smart" enough. After digging into their systems, I discovered they use a "Smart Object" pattern. In this mode, objects in the world are active, they constantly broadcast their functions to the surroundings. A fridge shouts, "I have food!" while a TV broadcasts, "I am fun!" While this significantly reduces the logic load on the NPCs, it creates a drawback I find difficult to overlook: NPCs become passive "receivers." They lack internal drive and feel more like puppets pulled by environmental strings rather than autonomous agents with a true sense of "intelligence."

Of course, even The Sims 4 is over a decade old now. Even with constant updates, the core logic is hard to change fundamentally. I have to admit, given how complex the animations and social systems are in The Sims, the developers have likely done an incredible job balancing performance and behavior. Even with newer competitors like inZoi, the NPCs still don't quite feel like they've broken out of that "reactive" mold.

This leads me to another game I deeply admire: RimWorld. Despite being a much more lightweight 2D experience, the NPCs there feel like they have genuine "thoughts." They work, socialize, and live based on their own moods and memories. Even though much of this is expressed through simple text, it creates a deeply immersive experience. While RimWorld is essentially a survival game, the intelligence of its NPCs gave me a clear direction for my research.

After exploring the world of RimWorld and reading the book by its creator, Tynan Sylvester, I was particularly moved by his idea that "systemic emergence" comes from the autonomous combination of simple rules. In this "Pull" or "Scanner" mode, the NPC is an active observer. Every few moments, the NPC actively scans the environment to see what resources are available. What attracts me most to this approach is that decisions are based on a real-time match between internal needs and the current environment. The NPC isn't just waiting to be "woken up" by an object; they are actively seeking opportunities. This is the architecture I’ve chosen to explore—a Utility-based approach—to see how it truly differs from the Sims-style logic.

Finally, regarding the definition of my "Baseline." Since I want to make a comparison, I need a rival. Initially, I thought of a baseline that simply mirrored the "stiff" feel of traditional NPCs—those who only eat when starving or sleep when exhausted, with very little "free will." However, I realized that trying to perfectly replicate a Sims-style broadcasting system would introduce too many variables. I was worried I wouldn't be able to tell if the performance difference was due to the architecture itself or just the quality of my code implementation.

Therefore, I’ve decided that my Baseline will be a "Threshold Response Agent." It will use the exact same "Scanner" as my Utility agent, giving them identical perception of the world. The only difference will be the "brain." The baseline’s logic will be rigid; it won't act until a critical threshold is met. My goal with this design is to see if I can recreate that simple, robotic feel often found in older simulations. I’m curious to see: Can this Baseline agent even survive well in my environment? Will it behave like a predictable robot, or will it face unexpected "breakdowns" under pressure? I'm really looking forward to observing these results in the coming months.
